# Installing dependencies
!pip install pdfminer.six streamlit pickle5 langchain langchain-groq faiss-cpu huggingface_hub -q
!pip install -U langchain-community -q

# Imports
import os
import pickle
import time
from pdfminer.high_level import extract_text
from google.colab import files
from langchain_groq import ChatGroq
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# Constants
FAISS_STORE_PATH = "faiss_store.pkl"

# Initializing LLM
def initialize_llm():
    return ChatGroq(
        temperature=0,
        groq_api_key="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",
        model_name="llama-3.1-70b-versatile"
    )

# Uploadloading  and processing PDFs
def upload_and_process_pdfs():
    # Step 1: File upload
    uploaded_files = files.upload()
    all_text = ""
    for filename in uploaded_files.keys():
        print(f"Processing file: {filename}")
        extracted_text = extract_text(filename)
        all_text += extracted_text + "\n"
    print("All PDFs processed.")

    # Step 2: Spliting text into chunks
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    text_chunks = text_splitter.split_text(all_text)

    # Step 3: Creating embeddings and FAISS store
    print("Creating embeddings and FAISS index...")
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.from_texts(text_chunks, embeddings)

    # Step 4: Saving FAISS store
    with open(FAISS_STORE_PATH, "wb") as f:
        pickle.dump(vectorstore, f)
    print("FAISS index successfully built and saved!")

# Loading existing FAISS store
def load_faiss_store():
    if os.path.exists(FAISS_STORE_PATH):
        with open(FAISS_STORE_PATH, "rb") as f:
            return pickle.load(f)
    else:
        print("No FAISS index found. Please upload PDFs first.")
        return None

# Querying the vectorstore
def query_vectorstore(llm, vectorstore, query):
    print("\nProcessing your query...")
    chain = RetrievalQA.from_llm(llm=llm, retriever=vectorstore.as_retriever())
    result = chain.run(query)
    print("\nAnswer:")
    print(result)

# Main execution flow
def main():
    llm = initialize_llm()

    # Check if FAISS store already exists
    if not os.path.exists(FAISS_STORE_PATH):
        print("No FAISS index found. Uploading and processing PDFs...")
        upload_and_process_pdfs()
    else:
        print("FAISS index already exists. Skipping PDF processing.")

    # Loading the FAISS vectorstore
    vectorstore = load_faiss_store()

    if vectorstore:
        while True:
            query = input("\nAsk a Question (or type 'exit' to quit): ")
            if query.lower() == "exit":
                print("Exiting. Have a great day!")
                break
            query_vectorstore(llm, vectorstore, query)

# Running main
if __name__ == "__main__":
    main()
